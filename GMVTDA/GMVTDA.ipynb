{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-11-21T07:38:29.868950Z",
     "start_time": "2025-11-21T07:38:29.071516Z"
    }
   },
   "source": [
    "import scipy.io as sio\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def load_and_segment(mat_path, key='Channel_1', seg_len=1024, stride=1024):\n",
    "    \"\"\"读取 MAT 文件并按 seg_len 分段\"\"\"\n",
    "    mat = sio.loadmat(mat_path)\n",
    "    sig = mat[key].squeeze()\n",
    "    segments = []\n",
    "    for i in range(0, len(sig) - seg_len + 1, stride):\n",
    "        segments.append(sig[i:i+seg_len])\n",
    "    return np.array(segments)\n",
    "\n",
    "# -------------------------------\n",
    "# 1. 读取三个文件并分段\n",
    "# -------------------------------\n",
    "H_file = r\"D:\\deskbook\\科研\\数据集\\Ottawa\\H-D-1.mat\"\n",
    "I_file = r\"D:\\deskbook\\科研\\数据集\\Ottawa\\I-D-1.mat\"\n",
    "O_file = r\"D:\\deskbook\\科研\\数据集\\Ottawa\\O-D-1.mat\"\n",
    "\n",
    "H_segments = load_and_segment(H_file)\n",
    "I_segments = load_and_segment(I_file)\n",
    "O_segments = load_and_segment(O_file)\n",
    "\n",
    "print(\"H_A 总样本：\", len(H_segments))\n",
    "print(\"I_A 总样本：\", len(I_segments))\n",
    "print(\"O_A 总样本：\", len(O_segments))\n",
    "\n",
    "# -------------------------------\n",
    "# 2. 每类随机选取 300 个样本\n",
    "# -------------------------------\n",
    "def random_select(data, num=300):\n",
    "    idx = np.random.choice(len(data), num, replace=False)\n",
    "    return data[idx]\n",
    "\n",
    "H_sel = random_select(H_segments, 300)\n",
    "I_sel = random_select(I_segments, 300)\n",
    "O_sel = random_select(O_segments, 300)\n",
    "\n",
    "# -------------------------------\n",
    "# 3. 拼接并创建标签\n",
    "# -------------------------------\n",
    "data = np.vstack([H_sel, I_sel, O_sel])\n",
    "label = np.array([0]*300 + [1]*300 + [2]*300)\n",
    "\n",
    "print(\"最终数据 shape:\", data.shape)   # (900, 1024)\n",
    "print(\"标签 shape:\", label.shape)\n",
    "\n",
    "# -------------------------------\n",
    "# 4. 保存为 npy\n",
    "# -------------------------------\n",
    "np.save(\"data3.npy\", data.astype(np.float32))\n",
    "np.save(\"label3.npy\", label.astype(np.int64))\n",
    "\n",
    "print(\"已生成 data.npy 和 label.npy\")\n"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H_A 总样本： 1953\n",
      "I_A 总样本： 1953\n",
      "O_A 总样本： 1953\n",
      "最终数据 shape: (900, 1024)\n",
      "标签 shape: (900,)\n",
      "已生成 data.npy 和 label.npy\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T08:42:54.452319Z",
     "start_time": "2025-11-21T08:42:54.436777Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import math\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "\n",
    "# ==================== Dataset ====================\n",
    "class BearingDataset(Dataset):\n",
    "    def __init__(self, data, labels, transform=None):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx].astype(np.float32)\n",
    "        label = self.labels[idx]\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return torch.from_numpy(sample), torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "def create_dataloaders(source_idx, target_idx, batch_size=128):\n",
    "\n",
    "    source_data = np.load(f\"data{source_idx}.npy\")\n",
    "    source_labels = np.load(f\"label{source_idx}.npy\")\n",
    "    target_data = np.load(f\"data{target_idx}.npy\")\n",
    "    target_labels = np.load(f\"label{target_idx}.npy\")\n",
    "\n",
    "    print(f\"源域工况{source_idx}: {source_data.shape}, 目标域工况{target_idx}: {target_data.shape}\")\n",
    "\n",
    "    # 论文划分方式：630 train, 270 test\n",
    "    s_train = source_data[:630]\n",
    "    s_train_label = source_labels[:630]\n",
    "\n",
    "    t_train = target_data[:630]\n",
    "    t_test = target_data[630:900]\n",
    "    t_test_label = target_labels[630:900]\n",
    "\n",
    "    source_loader = DataLoader(\n",
    "        BearingDataset(s_train, s_train_label),\n",
    "        batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    target_train_loader = DataLoader(\n",
    "        BearingDataset(t_train, np.zeros(len(t_train))),\n",
    "        batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "\n",
    "    target_test_loader = DataLoader(\n",
    "        BearingDataset(t_test, t_test_label),\n",
    "        batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    print(f\"源域训练样本: {len(s_train)}\")\n",
    "    print(f\"目标域训练样本: {len(t_train)}\")\n",
    "    print(f\"目标域测试样本: {len(t_test)}\")\n",
    "\n",
    "    return source_loader, target_train_loader, target_test_loader"
   ],
   "id": "53fdc6622292fb71",
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T08:41:45.255871Z",
     "start_time": "2025-11-21T08:41:45.232690Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==================== Position Encoding ====================\n",
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pos = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0)/d_model))\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        pe = pe.unsqueeze(1)\n",
    "        self.register_buffer(\"pe\", pe)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:x.size(0)]\n",
    "\n",
    "# ==================== Transformer Encoder Layer ====================\n",
    "class CustomTransformerEncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, nhead, dim_feedforward=512, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(d_model, nhead, dropout=dropout, batch_first=False)\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.drop1 = nn.Dropout(dropout)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, dim_feedforward),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(dim_feedforward, d_model)\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        r, _ = self.attn(x, x, x)\n",
    "        x = self.norm1(x + self.drop1(r))\n",
    "        r2 = self.ff(x)\n",
    "        return self.norm2(x + r2)\n",
    "\n",
    "# ==================== CNN + Transformer Feature Extractor ====================\n",
    "class FeatureExtractor(nn.Module):\n",
    "    def __init__(self, input_length=1024, feature_dim=256):\n",
    "        super().__init__()\n",
    "\n",
    "        self.c1 = nn.Conv1d(1, 64, 7, padding=3)\n",
    "        self.b1 = nn.BatchNorm1d(64)\n",
    "        self.p1 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.c2 = nn.Conv1d(64, 128, 5, padding=2)\n",
    "        self.b2 = nn.BatchNorm1d(128)\n",
    "        self.p2 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.c3 = nn.Conv1d(128, 256, 3, padding=1)\n",
    "        self.b3 = nn.BatchNorm1d(256)\n",
    "        self.p3 = nn.MaxPool1d(2)\n",
    "\n",
    "        self.p4 = nn.AdaptiveAvgPool1d(16)\n",
    "\n",
    "        d_model = 256\n",
    "        self.pos = PositionalEncoding(d_model)\n",
    "\n",
    "        enc = CustomTransformerEncoderLayer(d_model, 8, 512, 0.1)\n",
    "        self.trans = nn.TransformerEncoder(enc, num_layers=2)\n",
    "\n",
    "        self.proj = nn.Linear(256, feature_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.unsqueeze(1)\n",
    "        x = self.p1(F.relu(self.b1(self.c1(x))))\n",
    "        x = self.p2(F.relu(self.b2(self.c2(x))))\n",
    "        x = self.p3(F.relu(self.b3(self.c3(x))))\n",
    "        x = self.p4(x)\n",
    "\n",
    "        x = x.permute(2, 0, 1)\n",
    "        x = self.pos(x)\n",
    "        x = self.trans(x)\n",
    "\n",
    "        x = x.permute(1, 2, 0)\n",
    "        x = F.adaptive_avg_pool1d(x, 1).squeeze(-1)\n",
    "        return self.proj(x)"
   ],
   "id": "4412de5e1e2284ec",
   "outputs": [],
   "execution_count": 29
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T08:41:47.565874Z",
     "start_time": "2025-11-21T08:41:47.531244Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "# ==================== Gaussian Mixture CAD ====================\n",
    "class GaussianMixtureCAD(nn.Module):\n",
    "    \"\"\"\n",
    "    CAD: p_beta(z|w,c) mixture of Gaussians whose means depend on w.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_components=3, latent_dim=1, w_dim=8):\n",
    "        super().__init__()\n",
    "        self.K = num_components\n",
    "        self.D = latent_dim\n",
    "        self.w_dim = w_dim\n",
    "\n",
    "        self.base_means = nn.Parameter(torch.randn(self.K, self.D) * 0.01)\n",
    "        self.base_logvars = nn.Parameter(torch.zeros(self.K, self.D))\n",
    "\n",
    "        self.w_to_mean = nn.Parameter(torch.randn(self.K, self.w_dim, self.D) * 0.01)\n",
    "\n",
    "    def forward(self, z, w=None, labels=None):\n",
    "\n",
    "        B = z.size(0)\n",
    "        K, D = self.K, self.D\n",
    "\n",
    "        if w is None:\n",
    "            mu_eff = self.base_means.unsqueeze(0).expand(B, K, D)\n",
    "        else:\n",
    "            shift = torch.einsum('bw,kwd->bkd', w, self.w_to_mean)\n",
    "            mu_eff = self.base_means.unsqueeze(0) + shift\n",
    "\n",
    "        var_eff = torch.exp(self.base_logvars).unsqueeze(0).expand(B, K, D)\n",
    "\n",
    "        z_exp = z.unsqueeze(1)\n",
    "        term = -0.5 * torch.sum(((z_exp - mu_eff)**2)/var_eff + torch.log(2*math.pi*var_eff), dim=2)\n",
    "        term = term - term.max(dim=1, keepdim=True).values\n",
    "        p = F.softmax(term, dim=1)\n",
    "\n",
    "        if labels is not None:\n",
    "            return F.one_hot(labels, K).float(), {\"mu\": mu_eff, \"var\": var_eff}\n",
    "\n",
    "        return p, {\"mu\": mu_eff, \"var\": var_eff}\n",
    "\n",
    "# ==================== Domain Alignment Module ====================\n",
    "class DomainAlignmentModule(nn.Module):\n",
    "    def __init__(self, feature_dim=256, num_classes=3, z_dim=1, w_dim=8):\n",
    "        super().__init__()\n",
    "\n",
    "        self.z_dim = z_dim\n",
    "        self.w_dim = w_dim\n",
    "        self.K = num_classes\n",
    "\n",
    "        # φw recognition net\n",
    "        self.w_fc = nn.Linear(feature_dim, 128)\n",
    "        self.w_mu = nn.Linear(128, w_dim)\n",
    "        self.w_logv = nn.Linear(128, w_dim)\n",
    "\n",
    "        # φz recognition net\n",
    "        self.z_fc = nn.Linear(feature_dim, 128)\n",
    "        self.z_mu = nn.Linear(128, z_dim)\n",
    "        self.z_logv = nn.Linear(128, z_dim)\n",
    "\n",
    "        # q(c|x)\n",
    "        self.comp_net = nn.Sequential(\n",
    "            nn.Linear(feature_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, num_classes)\n",
    "        )\n",
    "\n",
    "        # CAD\n",
    "        self.cad = GaussianMixtureCAD(num_components=num_classes, latent_dim=z_dim, w_dim=w_dim)\n",
    "\n",
    "    def rep(self, mu, logv):\n",
    "        std = torch.exp(0.5 * logv)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        h_w = F.relu(self.w_fc(x))\n",
    "        mu_w, logv_w = self.w_mu(h_w), self.w_logv(h_w)\n",
    "        w = self.rep(mu_w, logv_w)\n",
    "\n",
    "        h_z = F.relu(self.z_fc(x))\n",
    "        mu_z, logv_z = self.z_mu(h_z), self.z_logv(h_z)\n",
    "        z = self.rep(mu_z, logv_z)\n",
    "\n",
    "        p_q = F.softmax(self.comp_net(x), dim=1)\n",
    "\n",
    "        p_beta, info = self.cad(z, w, labels)\n",
    "\n",
    "        return {\n",
    "            \"w\": w, \"mu_w\": mu_w, \"logv_w\": logv_w,\n",
    "            \"z\": z, \"mu_z\": mu_z, \"logv_z\": logv_z,\n",
    "            \"p_q\": p_q, \"p_beta\": p_beta,\n",
    "            \"mu_eff\": info[\"mu\"], \"var_eff\": info[\"var\"]\n",
    "        }\n",
    "\n",
    "# ==================== Classifier ====================\n",
    "class HealthClassifier(nn.Module):\n",
    "    def __init__(self, in_dim=256, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(in_dim, 128), nn.ReLU(),\n",
    "            nn.Linear(128, 64), nn.ReLU(),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "# ==================== GMVTDA Model ====================\n",
    "class GMVTDA(nn.Module):\n",
    "    def __init__(self, input_length=1024, feature_dim=256, num_classes=3, z_dim=1, w_dim=8):\n",
    "        super().__init__()\n",
    "        self.feat = FeatureExtractor(input_length, feature_dim)\n",
    "        self.align = DomainAlignmentModule(feature_dim, num_classes, z_dim, w_dim)\n",
    "        self.clf = HealthClassifier(feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        f = self.feat(x)\n",
    "        align = self.align(f, labels)\n",
    "        logit = self.clf(f)\n",
    "        return {\"feat\": f, \"health\": logit, \"align\": align}"
   ],
   "id": "3b10216c0633ddc6",
   "outputs": [],
   "execution_count": 30
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T08:41:50.533263Z",
     "start_time": "2025-11-21T08:41:50.525106Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# ==================== GMVTDA Loss ====================\n",
    "class GMVTDALoss:\n",
    "    def __init__(self, num_classes=3):\n",
    "        self.K = num_classes\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def kl_N(self, mu, logv):\n",
    "        return 0.5 * torch.sum(mu**2 + logv.exp() - logv - 1, dim=1)\n",
    "\n",
    "    def LW(self, mu_w, logv_w):\n",
    "        return torch.mean(self.kl_N(mu_w, logv_w))\n",
    "\n",
    "    def LC(self, p_beta):\n",
    "        K = p_beta.size(1)\n",
    "        log_p = torch.log(p_beta + 1e-12)\n",
    "        u = -math.log(K)\n",
    "        return torch.mean(torch.sum(p_beta * (log_p - u), dim=1))\n",
    "\n",
    "    def LGK(self, mu_z, logv_z, p_beta, mu_eff, var_eff):\n",
    "\n",
    "        B, K, D = mu_eff.shape\n",
    "\n",
    "        mu_q = mu_z.unsqueeze(1).expand(B, K, D)\n",
    "        logv_q = logv_z.unsqueeze(1).expand(B, K, D)\n",
    "        var_q = torch.exp(logv_q)\n",
    "\n",
    "        kl = 0.5 * torch.sum(\n",
    "            torch.log(var_eff + 1e-12) - logv_q +\n",
    "            (var_q + (mu_q - mu_eff)**2) / (var_eff + 1e-12) - 1,\n",
    "            dim=2\n",
    "        )\n",
    "\n",
    "        return torch.mean(torch.sum(p_beta * kl, dim=1))\n",
    "\n",
    "    def __call__(self, out, source_labels=None):\n",
    "\n",
    "        align = out[\"align\"]\n",
    "\n",
    "        if source_labels is not None:\n",
    "            LH = self.ce(out[\"health\"], source_labels)\n",
    "        else:\n",
    "            LH = torch.tensor(0.0, device=out[\"health\"].device)\n",
    "\n",
    "        L_W = self.LW(align[\"mu_w\"], align[\"logv_w\"])\n",
    "        L_C = self.LC(align[\"p_beta\"])\n",
    "        L_GK = self.LGK(align[\"mu_z\"], align[\"logv_z\"], align[\"p_beta\"], align[\"mu_eff\"], align[\"var_eff\"])\n",
    "\n",
    "        L_DA = L_W + L_C + L_GK\n",
    "\n",
    "        return LH, L_DA, {\"LH\": LH.item(), \"LW\": L_W.item(), \"LC\": L_C.item(), \"LGK\": L_GK.item()}"
   ],
   "id": "113aff5398826ac9",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T08:41:52.461261Z",
     "start_time": "2025-11-21T08:41:52.453534Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_epoch(model, s_loader, t_loader, optim, criterion, device, epoch, total_epochs):\n",
    "\n",
    "    model.train()\n",
    "    total = 0\n",
    "\n",
    "    N = min(len(s_loader), len(t_loader))\n",
    "    s_it = iter(s_loader)\n",
    "    t_it = iter(t_loader)\n",
    "\n",
    "    q = epoch / total_epochs\n",
    "    alpha = 2 / (1 + math.exp(-10*q)) - 1\n",
    "\n",
    "    for _ in range(N):\n",
    "        xs, ys = next(s_it)\n",
    "        xt, _ = next(t_it)\n",
    "\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "        xt = xt.to(device)\n",
    "\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # Source\n",
    "        out_s = model(xs, ys)\n",
    "        LH_s, LDA_s, _ = criterion(out_s, ys)\n",
    "\n",
    "        # Target\n",
    "        out_t = model(xt)\n",
    "        LH_t, LDA_t, _ = criterion(out_t, None)\n",
    "\n",
    "        loss = LH_s + alpha*(LDA_s + LDA_t)\n",
    "\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "\n",
    "        total += loss.item()\n",
    "\n",
    "    return total / N, alpha\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            pred = out[\"health\"].argmax(1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += len(y)\n",
    "    return correct / total * 100\n"
   ],
   "id": "32a40e7e27345146",
   "outputs": [],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T08:41:55.525295Z",
     "start_time": "2025-11-21T08:41:54.082936Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def main_training(source_domain=0, target_domain=1):\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"使用设备:\", device)\n",
    "\n",
    "    batch = 128\n",
    "    z_dim = 1\n",
    "    w_dim = 8\n",
    "    feat_dim = 256\n",
    "    classes = 3\n",
    "    epochs = 300\n",
    "    lr = 1e-4\n",
    "\n",
    "    s_loader, t_loader, t_test_loader = create_dataloaders(source_domain, target_domain, batch)\n",
    "\n",
    "    model = GMVTDA(1024, feat_dim, classes, z_dim, w_dim).to(device)\n",
    "    optim = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    sched = torch.optim.lr_scheduler.MultiStepLR(optim, [150, 250], gamma=0.1)\n",
    "    crit = GMVTDALoss(classes)\n",
    "\n",
    "    print(\"模型参数数量:\", sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        loss, alpha = train_epoch(model, s_loader, t_loader, optim, crit, device, ep, epochs)\n",
    "        sched.step()\n",
    "\n",
    "        if (ep+1) % 50 == 0 or ep == 0:\n",
    "            acc_s = evaluate(model, s_loader, device)\n",
    "            acc_t = evaluate(model, t_test_loader, device)\n",
    "            print(f\"[Epoch {ep+1}/{epochs}] Loss={loss:.4f} Alpha={alpha:.3f} | Source={acc_s:.2f}% Target={acc_t:.2f}%\")\n",
    "\n",
    "    final_s = evaluate(model, s_loader, device)\n",
    "    final_t = evaluate(model, t_test_loader, device)\n",
    "    print(f\"最终源域准确率: {final_s:.2f}%\")\n",
    "    print(f\"最终目标域准确率: {final_t:.2f}%\")\n",
    "\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    torch.save(model.state_dict(), f\"gmvtda_{source_domain}to{target_domain}_{ts}.pth\")\n",
    "\n",
    "    return model, final_s, final_t\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=\"*60)\n",
    "    print(\"GMVTDA 域适应故障诊断\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    model, acc_s, acc_t = main_training(0, 1)\n"
   ],
   "id": "89a6b1211c2b7d1d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "GMVTDA 域适应故障诊断\n",
      "============================================================\n",
      "使用设备: cuda\n",
      "源域工况0: (900, 1024), 目标域工况1: (900, 1024)\n",
      "源域训练样本: 630\n",
      "目标域训练样本: 630\n",
      "目标域测试样本: 270\n",
      "模型参数数量: 1403830\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'CustomTransformerEncoderLayer' object has no attribute 'self_attn'",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mAttributeError\u001B[39m                            Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[33]\u001B[39m\u001B[32m, line 48\u001B[39m\n\u001B[32m     45\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33mGMVTDA 域适应故障诊断\u001B[39m\u001B[33m\"\u001B[39m)\n\u001B[32m     46\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m=\u001B[39m\u001B[33m\"\u001B[39m*\u001B[32m60\u001B[39m)\n\u001B[32m---> \u001B[39m\u001B[32m48\u001B[39m model, acc_s, acc_t = \u001B[43mmain_training\u001B[49m\u001B[43m(\u001B[49m\u001B[32;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[32;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[33]\u001B[39m\u001B[32m, line 24\u001B[39m, in \u001B[36mmain_training\u001B[39m\u001B[34m(source_domain, target_domain)\u001B[39m\n\u001B[32m     21\u001B[39m \u001B[38;5;28mprint\u001B[39m(\u001B[33m\"\u001B[39m\u001B[33m模型参数数量:\u001B[39m\u001B[33m\"\u001B[39m, \u001B[38;5;28msum\u001B[39m(p.numel() \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m model.parameters()))\n\u001B[32m     23\u001B[39m \u001B[38;5;28;01mfor\u001B[39;00m ep \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m     loss, alpha = \u001B[43mtrain_epoch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43ms_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mt_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptim\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcrit\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mep\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     25\u001B[39m     sched.step()\n\u001B[32m     27\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m (ep+\u001B[32m1\u001B[39m) % \u001B[32m50\u001B[39m == \u001B[32m0\u001B[39m \u001B[38;5;129;01mor\u001B[39;00m ep == \u001B[32m0\u001B[39m:\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[32]\u001B[39m\u001B[32m, line 23\u001B[39m, in \u001B[36mtrain_epoch\u001B[39m\u001B[34m(model, s_loader, t_loader, optim, criterion, device, epoch, total_epochs)\u001B[39m\n\u001B[32m     20\u001B[39m optim.zero_grad()\n\u001B[32m     22\u001B[39m \u001B[38;5;66;03m# Source\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m23\u001B[39m out_s = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mxs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mys\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     24\u001B[39m LH_s, LDA_s, _ = criterion(out_s, ys)\n\u001B[32m     26\u001B[39m \u001B[38;5;66;03m# Target\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\EWSnet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\EWSnet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[30]\u001B[39m\u001B[32m, line 115\u001B[39m, in \u001B[36mGMVTDA.forward\u001B[39m\u001B[34m(self, x, labels)\u001B[39m\n\u001B[32m    114\u001B[39m \u001B[38;5;28;01mdef\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[34mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x, labels=\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[32m--> \u001B[39m\u001B[32m115\u001B[39m     f = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mfeat\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    116\u001B[39m     align = \u001B[38;5;28mself\u001B[39m.align(f, labels)\n\u001B[32m    117\u001B[39m     logit = \u001B[38;5;28mself\u001B[39m.clf(f)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\EWSnet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\EWSnet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[29]\u001B[39m\u001B[32m, line 73\u001B[39m, in \u001B[36mFeatureExtractor.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     71\u001B[39m x = x.permute(\u001B[32m2\u001B[39m, \u001B[32m0\u001B[39m, \u001B[32m1\u001B[39m)\n\u001B[32m     72\u001B[39m x = \u001B[38;5;28mself\u001B[39m.pos(x)\n\u001B[32m---> \u001B[39m\u001B[32m73\u001B[39m x = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtrans\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     75\u001B[39m x = x.permute(\u001B[32m1\u001B[39m, \u001B[32m2\u001B[39m, \u001B[32m0\u001B[39m)\n\u001B[32m     76\u001B[39m x = F.adaptive_avg_pool1d(x, \u001B[32m1\u001B[39m).squeeze(-\u001B[32m1\u001B[39m)\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\EWSnet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1734\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1735\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1736\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\EWSnet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1742\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1743\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1744\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1745\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1746\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1747\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1749\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1750\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\EWSnet\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:431\u001B[39m, in \u001B[36mTransformerEncoder.forward\u001B[39m\u001B[34m(self, src, mask, src_key_padding_mask, is_causal)\u001B[39m\n\u001B[32m    429\u001B[39m why_not_sparsity_fast_path = \u001B[33m\"\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m    430\u001B[39m str_first_layer = \u001B[33m\"\u001B[39m\u001B[33mself.layers[0]\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m--> \u001B[39m\u001B[32m431\u001B[39m batch_first = \u001B[43mfirst_layer\u001B[49m\u001B[43m.\u001B[49m\u001B[43mself_attn\u001B[49m.batch_first\n\u001B[32m    432\u001B[39m is_fastpath_enabled = torch.backends.mha.get_fastpath_enabled()\n\u001B[32m    434\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m is_fastpath_enabled:\n",
      "\u001B[36mFile \u001B[39m\u001B[32mD:\\anaconda3\\envs\\EWSnet\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1931\u001B[39m, in \u001B[36mModule.__getattr__\u001B[39m\u001B[34m(self, name)\u001B[39m\n\u001B[32m   1929\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01min\u001B[39;00m modules:\n\u001B[32m   1930\u001B[39m         \u001B[38;5;28;01mreturn\u001B[39;00m modules[name]\n\u001B[32m-> \u001B[39m\u001B[32m1931\u001B[39m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mAttributeError\u001B[39;00m(\n\u001B[32m   1932\u001B[39m     \u001B[33mf\u001B[39m\u001B[33m\"\u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mtype\u001B[39m(\u001B[38;5;28mself\u001B[39m).\u001B[34m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m object has no attribute \u001B[39m\u001B[33m'\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mname\u001B[38;5;132;01m}\u001B[39;00m\u001B[33m'\u001B[39m\u001B[33m\"\u001B[39m\n\u001B[32m   1933\u001B[39m )\n",
      "\u001B[31mAttributeError\u001B[39m: 'CustomTransformerEncoderLayer' object has no attribute 'self_attn'"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-11-21T09:06:42.605508Z",
     "start_time": "2025-11-21T09:01:44.785718Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "\n",
    "import os\n",
    "import math\n",
    "import time\n",
    "import random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# -------------------------\n",
    "# utils\n",
    "# -------------------------\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "def normalize_sample(x):\n",
    "    \"\"\"逐样本归一化：zero mean, unit std，防止 std=0\"\"\"\n",
    "    x = x.astype(np.float32)\n",
    "    m = np.mean(x, axis=-1, keepdims=True)\n",
    "    s = np.std(x, axis=-1, keepdims=True)\n",
    "    s[s < 1e-6] = 1.0\n",
    "    return ((x - m) / s).astype(np.float32)\n",
    "\n",
    "# -------------------------\n",
    "# Dataset / DataLoader\n",
    "# -------------------------\n",
    "class BearingDataset(Dataset):\n",
    "    def __init__(self, data: np.ndarray, labels: np.ndarray = None, transform=None):\n",
    "        # data: (N, L) or (N,1,L)\n",
    "        if data.ndim == 2:\n",
    "            data = data[:, None, :]\n",
    "        self.data = data.astype(np.float32)\n",
    "        if labels is None:\n",
    "            self.labels = None\n",
    "        else:\n",
    "            self.labels = labels.astype(np.int64)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data) if self.labels is None else len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.data[idx]\n",
    "        if self.transform:\n",
    "            x = self.transform(x)\n",
    "        if self.labels is None:\n",
    "            return torch.from_numpy(x), -1\n",
    "        else:\n",
    "            return torch.from_numpy(x), torch.tensor(self.labels[idx], dtype=torch.long)\n",
    "\n",
    "def build_loaders_from_npy(source_idx, target_idx, batch_domain=128, seg_len=1024, normalize=True):\n",
    "    sdata = np.load(f\"data{source_idx}.npy\")  # (900, 1024)\n",
    "    slabel = np.load(f\"label{source_idx}.npy\")\n",
    "    tdata = np.load(f\"data{target_idx}.npy\")\n",
    "    tlabel = np.load(f\"label{target_idx}.npy\")\n",
    "\n",
    "    if normalize:\n",
    "        sdata = normalize_sample(sdata)\n",
    "        tdata = normalize_sample(tdata)\n",
    "\n",
    "    # per paper: first 630 train, last 270 test\n",
    "    s_train_x, s_train_y = sdata[:630], slabel[:630]\n",
    "    t_train_x = tdata[:630]       # unsupervised target train (no labels passed)\n",
    "    t_test_x, t_test_y = tdata[630:900], tlabel[630:900]\n",
    "\n",
    "    src_ds = BearingDataset(s_train_x, s_train_y, transform=None)\n",
    "    tgt_train_ds = BearingDataset(t_train_x, None, transform=None)  # labels none; __getitem__ returns -1 for label\n",
    "    tgt_test_ds = BearingDataset(t_test_x, t_test_y, transform=None)\n",
    "\n",
    "    src_loader = DataLoader(src_ds, batch_size=batch_domain, shuffle=True, drop_last=True)\n",
    "    tgt_train_loader = DataLoader(tgt_train_ds, batch_size=batch_domain, shuffle=True, drop_last=True)\n",
    "    tgt_test_loader = DataLoader(tgt_test_ds, batch_size=batch_domain, shuffle=False)\n",
    "\n",
    "    return src_loader, tgt_train_loader, tgt_test_loader\n",
    "\n",
    "# -------------------------\n",
    "# Model components\n",
    "# -------------------------\n",
    "class PositionalEncodingBatchFirst(nn.Module):\n",
    "    \"\"\"Positional encoding that supports batch_first input shape: (B, S, D)\"\"\"\n",
    "    def __init__(self, d_model, max_len=5000):\n",
    "        super().__init__()\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n",
    "        pe[:, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 1::2] = torch.cos(position * div_term)\n",
    "        # store as (1, max_len, d_model) for easy addition to batch_first inputs\n",
    "        self.register_buffer('pe', pe.unsqueeze(0))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, S, D)\n",
    "        L = x.size(1)\n",
    "        return x + self.pe[:, :L, :]\n",
    "\n",
    "class FeatureExtractor(nn.Module):\n",
    "    \"\"\"1D CNN -> Transformer (batch_first=True) -> global pool -> projection\"\"\"\n",
    "    def __init__(self, input_length=1024, feat_dim=128, nhead=8):\n",
    "        super().__init__()\n",
    "        assert feat_dim % nhead == 0, \"feat_dim must be divisible by nhead\"\n",
    "        self.conv1 = nn.Conv1d(1, 32, kernel_size=7, padding=3)\n",
    "        self.bn1 = nn.BatchNorm1d(32)\n",
    "        self.pool = nn.MaxPool1d(2)\n",
    "        self.conv2 = nn.Conv1d(32, 64, kernel_size=5, padding=2)\n",
    "        self.bn2 = nn.BatchNorm1d(64)\n",
    "        self.conv3 = nn.Conv1d(64, feat_dim, kernel_size=3, padding=1)\n",
    "        self.bn3 = nn.BatchNorm1d(feat_dim)\n",
    "\n",
    "        # positional encoding and transformer (batch_first=True)\n",
    "        self.pos = PositionalEncodingBatchFirst(feat_dim)\n",
    "        layer = nn.TransformerEncoderLayer(d_model=feat_dim, nhead=nhead, dim_feedforward=512, batch_first=True)\n",
    "        self.transformer = nn.TransformerEncoder(layer, num_layers=2)\n",
    "\n",
    "        self.global_pool = nn.AdaptiveAvgPool1d(1)\n",
    "        self.proj = nn.Linear(feat_dim, feat_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 1, L)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.bn3(self.conv3(x)))  # (B, feat_dim, L')\n",
    "        # prepare for transformer with batch_first\n",
    "        x_tf = x.permute(0, 2, 1)  # (B, S, D)\n",
    "        x_tf = self.pos(x_tf)\n",
    "        x_tf = self.transformer(x_tf)  # (B, S, D)\n",
    "        x_tf = x_tf.permute(0, 2, 1)  # (B, D, S)\n",
    "        f = self.global_pool(x_tf).squeeze(-1)  # (B, D)\n",
    "        return self.proj(f)\n",
    "\n",
    "# CAD: Gaussian Mixture with w->mu modulation\n",
    "class GaussianMixtureCAD(nn.Module):\n",
    "    def __init__(self, num_components=3, latent_dim=1, w_dim=8):\n",
    "        super().__init__()\n",
    "        self.K = num_components\n",
    "        self.D = latent_dim\n",
    "        self.w_dim = w_dim\n",
    "        # base params per component\n",
    "        self.base_means = nn.Parameter(torch.randn(self.K, self.D) * 0.01)\n",
    "        self.base_logvars = nn.Parameter(torch.zeros(self.K, self.D))\n",
    "        # mapping from w to mean shifts: (K, w_dim, D)\n",
    "        self.w_to_mean = nn.Parameter(torch.randn(self.K, self.w_dim, self.D) * 0.01)\n",
    "\n",
    "    def forward(self, z, w=None, labels=None):\n",
    "        B = z.size(0)\n",
    "        K, D = self.K, self.D\n",
    "        if w is None:\n",
    "            mu_eff = self.base_means.unsqueeze(0).expand(B, K, D)\n",
    "        else:\n",
    "            # w: (B, w_dim) ; w_to_mean: (K, w_dim, D) -> shift: (B, K, D)\n",
    "            shift = torch.einsum('bw,kwd->bkd', w, self.w_to_mean)\n",
    "            mu_eff = self.base_means.unsqueeze(0) + shift  # (B,K,D)\n",
    "        var_eff = torch.exp(self.base_logvars).unsqueeze(0).expand(B, K, D)  # (B,K,D)\n",
    "        z_exp = z.unsqueeze(1)  # (B,1,D)\n",
    "        # log p(z|w,c) up to constant\n",
    "        logp = -0.5 * torch.sum(((z_exp - mu_eff)**2) / (var_eff + 1e-12) + torch.log(2*math.pi*(var_eff + 1e-12)), dim=2)  # (B,K)\n",
    "        logp = logp - logp.max(dim=1, keepdim=True).values\n",
    "        p = F.softmax(logp, dim=1)  # (B,K)\n",
    "        if labels is not None:\n",
    "            return F.one_hot(labels, self.K).float(), {'mu_eff': mu_eff, 'var_eff': var_eff}\n",
    "        return p, {'mu_eff': mu_eff, 'var_eff': var_eff}\n",
    "\n",
    "class DomainAlignmentModule(nn.Module):\n",
    "    def __init__(self, feat_dim=128, num_classes=3, z_dim=1, w_dim=8):\n",
    "        super().__init__()\n",
    "        self.K = num_classes\n",
    "        self.z_dim = z_dim\n",
    "        self.w_dim = w_dim\n",
    "        # phi_w\n",
    "        self.w_fc = nn.Linear(feat_dim, 128)\n",
    "        self.w_mu = nn.Linear(128, w_dim)\n",
    "        self.w_logv = nn.Linear(128, w_dim)\n",
    "        # phi_z\n",
    "        self.z_fc = nn.Linear(feat_dim, 128)\n",
    "        self.z_mu = nn.Linear(128, z_dim)\n",
    "        self.z_logv = nn.Linear(128, z_dim)\n",
    "        # q(c|x) optional net\n",
    "        self.comp_net = nn.Sequential(nn.Linear(feat_dim,128), nn.ReLU(), nn.Linear(128, num_classes))\n",
    "        # CAD\n",
    "        self.cad = GaussianMixtureCAD(num_components=num_classes, latent_dim=z_dim, w_dim=w_dim)\n",
    "\n",
    "    def rep(self, mu, logv):\n",
    "        std = torch.exp(0.5 * logv)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        # x: (B, feat_dim)\n",
    "        h_w = F.relu(self.w_fc(x))\n",
    "        mu_w = self.w_mu(h_w)\n",
    "        logv_w = self.w_logv(h_w)\n",
    "        w = self.rep(mu_w, logv_w)\n",
    "\n",
    "        h_z = F.relu(self.z_fc(x))\n",
    "        mu_z = self.z_mu(h_z)\n",
    "        logv_z = self.z_logv(h_z)\n",
    "        z = self.rep(mu_z, logv_z)\n",
    "\n",
    "        comp_q = F.softmax(self.comp_net(x), dim=1)\n",
    "        p_beta, info = self.cad(z, w, labels)\n",
    "\n",
    "        # info: mu_eff (B,K,D), var_eff (B,K,D)\n",
    "        return {\n",
    "            'w': w, 'mu_w': mu_w, 'logv_w': logv_w,\n",
    "            'z': z, 'mu_z': mu_z, 'logv_z': logv_z,\n",
    "            'comp_q': comp_q, 'p_beta': p_beta,\n",
    "            'mu_eff': info['mu_eff'], 'var_eff': info['var_eff']\n",
    "        }\n",
    "\n",
    "class HealthClassifier(nn.Module):\n",
    "    def __init__(self, feat_dim=128, num_classes=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(feat_dim, 128), nn.ReLU(), nn.Dropout(0.3),\n",
    "            nn.Linear(128, 64), nn.ReLU(), nn.Dropout(0.2),\n",
    "            nn.Linear(64, num_classes)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.net(x)\n",
    "\n",
    "class GMVTDA(nn.Module):\n",
    "    def __init__(self, input_length=1024, feat_dim=128, num_classes=3, z_dim=1, w_dim=8):\n",
    "        super().__init__()\n",
    "        self.feat = FeatureExtractor(input_length, feat_dim)\n",
    "        self.align = DomainAlignmentModule(feat_dim, num_classes, z_dim, w_dim)\n",
    "        self.clf = HealthClassifier(feat_dim, num_classes)\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        # x: (B,1,L)\n",
    "        feats = self.feat(x)  # (B, feat_dim)\n",
    "        align_out = self.align(feats, labels)\n",
    "        logits = self.clf(feats)\n",
    "        return {'feat': feats, 'health': logits, 'align': align_out}\n",
    "\n",
    "# -------------------------\n",
    "# Loss (paper formulas)\n",
    "# -------------------------\n",
    "class GMVTDALoss:\n",
    "    def __init__(self, num_classes=3):\n",
    "        self.K = num_classes\n",
    "        self.ce = nn.CrossEntropyLoss()\n",
    "\n",
    "    def kl_normal(self, mu, logv):\n",
    "        # per-sample KL to N(0,I) summed across dims\n",
    "        return 0.5 * torch.sum(mu**2 + logv.exp() - logv - 1, dim=1)  # (B,)\n",
    "\n",
    "    def L_W(self, mu_w, logv_w):\n",
    "        return torch.mean(self.kl_normal(mu_w, logv_w))\n",
    "\n",
    "    def L_C(self, p_beta):\n",
    "        # KL(p_beta || uniform) = E_p_beta[ log p_beta - log 1/K ]\n",
    "        K = p_beta.size(1)\n",
    "        logp = torch.log(p_beta + 1e-12)\n",
    "        uniform_log = -math.log(K)\n",
    "        return torch.mean(torch.sum(p_beta * (logp - uniform_log), dim=1))\n",
    "\n",
    "    def L_GK(self, mu_z, logv_z, p_beta, mu_eff, var_eff):\n",
    "        # mu_z: (B,D); logv_z: (B,D)\n",
    "        B = mu_z.size(0)\n",
    "        D = mu_z.size(1)\n",
    "        K = p_beta.size(1)\n",
    "        # expand q params to (B,K,D)\n",
    "        mu_q = mu_z.unsqueeze(1).expand(B, K, D)\n",
    "        logv_q = logv_z.unsqueeze(1).expand(B, K, D)\n",
    "        var_q = torch.exp(logv_q)\n",
    "        mu_p = mu_eff  # (B,K,D)\n",
    "        var_p = var_eff  # (B,K,D)\n",
    "        # KL(q||p) per (B,K)\n",
    "        kl = 0.5 * torch.sum(torch.log(var_p + 1e-12) - logv_q + (var_q + (mu_q - mu_p)**2) / (var_p + 1e-12) - 1, dim=2)\n",
    "        # weight by p_beta\n",
    "        return torch.mean(torch.sum(p_beta * kl, dim=1))\n",
    "\n",
    "    def __call__(self, model_out, source_labels=None):\n",
    "        align = model_out['align']\n",
    "        if source_labels is not None and source_labels.nelement() > 0:\n",
    "            LH = self.ce(model_out['health'], source_labels)\n",
    "        else:\n",
    "            LH = torch.tensor(0.0, device=next(iter(model_out.values())).device)\n",
    "\n",
    "        Lw = self.L_W(align['mu_w'], align['logv_w'])\n",
    "        Lc = self.L_C(align['p_beta'])\n",
    "        Lgk = self.L_GK(align['mu_z'], align['logv_z'], align['p_beta'], align['mu_eff'], align['var_eff'])\n",
    "        L_DA = Lw + Lc + Lgk\n",
    "        return LH, L_DA, {'LH': LH.item(), 'Lw': Lw.item(), 'Lc': Lc.item(), 'Lgk': Lgk.item()}\n",
    "\n",
    "# -------------------------\n",
    "# training / eval utils\n",
    "# -------------------------\n",
    "def debug_pred_distribution(model, loader, device):\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device)\n",
    "            out = model(x)\n",
    "            p = out['health'].argmax(dim=1).cpu().numpy()\n",
    "            preds.append(p)\n",
    "    if len(preds) == 0:\n",
    "        return {}\n",
    "    allp = np.concatenate(preds)\n",
    "    unique, counts = np.unique(allp, return_counts=True)\n",
    "    dist = dict(zip(unique.tolist(), counts.tolist()))\n",
    "    print(\"Prediction distribution on loader:\", dist)\n",
    "    return dist\n",
    "\n",
    "def train_epoch(model, src_loader, tgt_loader, optimizer, criterion, device, epoch, total_epochs):\n",
    "    model.train()\n",
    "    total_batches = min(len(src_loader), len(tgt_loader))\n",
    "    s_it = iter(src_loader); t_it = iter(tgt_loader)\n",
    "    q = epoch / float(total_epochs)\n",
    "    alpha = 2.0 / (1.0 + math.exp(-10.0 * q)) - 1.0\n",
    "    running_loss = 0.0\n",
    "    for _ in range(total_batches):\n",
    "        xs, ys = next(s_it)\n",
    "        xt, _ = next(t_it)\n",
    "        xs, ys = xs.to(device), ys.to(device)\n",
    "        xt = xt.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out_s = model(xs, ys)\n",
    "        LH_s, LDA_s, _ = criterion(out_s, ys)\n",
    "\n",
    "        out_t = model(xt)\n",
    "        LH_t, LDA_t, _ = criterion(out_t, None)\n",
    "\n",
    "        loss = LH_s + alpha * (LDA_s + LDA_t)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    avg_loss = running_loss / total_batches\n",
    "    return avg_loss, alpha\n",
    "\n",
    "def evaluate(model, loader, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            out = model(x)\n",
    "            pred = out['health'].argmax(dim=1)\n",
    "            correct += (pred == y).sum().item()\n",
    "            total += y.size(0)\n",
    "    return 100.0 * correct / total if total > 0 else 0.0\n",
    "\n",
    "# -------------------------\n",
    "# main training script\n",
    "# -------------------------\n",
    "def run_experiment(source_domain=0, target_domain=1, device=None,\n",
    "                   batch_size=128, feat_dim=128, z_dim=1, w_dim=8,\n",
    "                   epochs=300, lr=1e-4, save_dir='checkpoints'):\n",
    "    set_seed(42)\n",
    "    device = device or (torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu'))\n",
    "    print(\"Device:\", device)\n",
    "\n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "    src_loader, tgt_train_loader, tgt_test_loader = build_loaders_from_npy(source_domain, target_domain, batch_domain=batch_size)\n",
    "\n",
    "    model = GMVTDA(input_length=1024, feat_dim=feat_dim, num_classes=3, z_dim=z_dim, w_dim=w_dim).to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[150, 250], gamma=0.1)\n",
    "    criterion = GMVTDALoss(num_classes=3)\n",
    "\n",
    "    print(\"Model params:\", sum(p.numel() for p in model.parameters()))\n",
    "\n",
    "    history = {'loss': [], 'alpha': [], 'src_acc': [], 'tgt_acc': []}\n",
    "\n",
    "    for ep in range(epochs):\n",
    "        loss, alpha = train_epoch(model, src_loader, tgt_train_loader, optimizer, criterion, device, ep, epochs)\n",
    "        scheduler.step()\n",
    "        history['loss'].append(loss)\n",
    "        history['alpha'].append(alpha)\n",
    "\n",
    "        if (ep + 1) % 50 == 0 or ep == 0:\n",
    "            src_acc = evaluate(model, src_loader, device)\n",
    "            tgt_acc = evaluate(model, tgt_test_loader, device)\n",
    "            history['src_acc'].append(src_acc)\n",
    "            history['tgt_acc'].append(tgt_acc)\n",
    "            print(f\"Epoch [{ep+1}/{epochs}] loss={loss:.4f} alpha={alpha:.4f} src_acc={src_acc:.2f}% tgt_acc={tgt_acc:.2f}%\")\n",
    "            debug_pred_distribution(model, tgt_test_loader, device)\n",
    "\n",
    "        # periodic checkpoint\n",
    "        if (ep + 1) % 100 == 0:\n",
    "            path = os.path.join(save_dir, f\"gmvtda_ep{ep+1}_s{source_domain}t{target_domain}.pth\")\n",
    "            torch.save({'epoch': ep+1, 'model': model.state_dict(), 'optim': optimizer.state_dict(), 'history': history}, path)\n",
    "            print(\"Saved checkpoint:\", path)\n",
    "\n",
    "    # final save\n",
    "    ts = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    final_path = os.path.join(save_dir, f\"gmvtda_final_s{source_domain}t{target_domain}_{ts}.pth\")\n",
    "    torch.save({'epoch': epochs, 'model': model.state_dict(), 'optim': optimizer.state_dict(), 'history': history}, final_path)\n",
    "    print(\"Saved final model:\", final_path)\n",
    "\n",
    "    # final eval\n",
    "    final_src_acc = evaluate(model, src_loader, device)\n",
    "    final_tgt_acc = evaluate(model, tgt_test_loader, device)\n",
    "    print(f\"Final Source Acc: {final_src_acc:.2f}%  Final Target Acc: {final_tgt_acc:.2f}%\")\n",
    "\n",
    "    # plot quick curves\n",
    "    try:\n",
    "        plt.figure(figsize=(10,4))\n",
    "        plt.subplot(1,2,1)\n",
    "        plt.plot(history['loss']); plt.title('Train loss'); plt.xlabel('Epoch')\n",
    "        plt.subplot(1,2,2)\n",
    "        plt.plot(history['alpha']); plt.title('Alpha schedule'); plt.xlabel('Epoch')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "    return model, history\n",
    "\n",
    "# -------------------------\n",
    "# run if main\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    # Example: train source domain 0 -> target domain 1\n",
    "    # Ensure files data0.npy,label0.npy ... exist in working dir\n",
    "    model, history = run_experiment(source_domain=0, target_domain=1, device=None,\n",
    "                                    batch_size=128, feat_dim=128, z_dim=1, w_dim=8,\n",
    "                                    epochs=300, lr=1e-4, save_dir='checkpoints')\n"
   ],
   "id": "b404223e50361d2e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n",
      "Model params: 526006\n",
      "Epoch [1/300] loss=1.0936 alpha=0.0000 src_acc=47.07% tgt_acc=0.00%\n",
      "Prediction distribution on loader: {1: 270}\n",
      "Epoch [50/300] loss=0.9015 alpha=0.6733 src_acc=94.73% tgt_acc=0.00%\n",
      "Prediction distribution on loader: {0: 244, 1: 26}\n",
      "Epoch [100/300] loss=1.0654 alpha=0.9289 src_acc=99.22% tgt_acc=39.26%\n",
      "Prediction distribution on loader: {0: 143, 1: 21, 2: 106}\n",
      "Saved checkpoint: checkpoints\\gmvtda_ep100_s0t1.pth\n",
      "Epoch [150/300] loss=1.0949 alpha=0.9862 src_acc=100.00% tgt_acc=38.52%\n",
      "Prediction distribution on loader: {0: 150, 1: 16, 2: 104}\n",
      "Epoch [200/300] loss=1.1020 alpha=0.9974 src_acc=100.00% tgt_acc=37.04%\n",
      "Prediction distribution on loader: {0: 151, 1: 19, 2: 100}\n",
      "Saved checkpoint: checkpoints\\gmvtda_ep200_s0t1.pth\n",
      "Epoch [250/300] loss=1.1017 alpha=0.9995 src_acc=100.00% tgt_acc=37.41%\n",
      "Prediction distribution on loader: {0: 146, 1: 23, 2: 101}\n",
      "Epoch [300/300] loss=1.1029 alpha=0.9999 src_acc=100.00% tgt_acc=37.04%\n",
      "Prediction distribution on loader: {0: 149, 1: 21, 2: 100}\n",
      "Saved checkpoint: checkpoints\\gmvtda_ep300_s0t1.pth\n",
      "Saved final model: checkpoints\\gmvtda_final_s0t1_20251121_170642.pth\n",
      "Final Source Acc: 100.00%  Final Target Acc: 37.04%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1000x400 with 2 Axes>"
      ],
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 37
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
